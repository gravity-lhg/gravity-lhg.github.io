<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Region Proposal by Guided Anchoring - 刘浩光的个人博客</title>
    <meta name="author"  content="刘浩光">
    <meta name="description" content="Region Proposal by Guided Anchoring">
    <meta name="keywords"  content="DeepLearning, ReadPaper">
    <!-- Open Graph -->
    <meta property="og:title" content="Region Proposal by Guided Anchoring - 刘浩光的个人博客">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://localhost:4000/2023/03/06/GA_RPN.html">
    <meta property="og:description" content="为天地立心, 为生民立命, 为往圣继绝学, 为万世开太平">
    <meta property="og:site_name" content="刘浩光的个人博客">
    <link rel="stylesheet" href="//cdn.staticfile.org/normalize/6.0.0/normalize.min.css">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_roc50gemkxpw4s4i.css">
    <link rel="stylesheet" href="/assets/css/github-markdown.css">
    <link rel="stylesheet" href="/assets/css/prism.css">
    <link rel="stylesheet" href="/assets/css/share.min.css">
    <link rel="stylesheet" href="/assets/css/app.min.css">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script>
	
	<!--
Author: Ray-Eldath
refer to:
 - http://docs.mathjax.org/en/latest/options/index.html
-->

	<script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
	
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
		jax: ["input/TeX", "output/HTML-CSS"],
		tex2jax: {
			inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
			displayMath: [ ["$$", "$$"], ["\\[","\\]"] ],
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		},
		"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
      });
    </script>


	
    <!--
Author: Ray-Eldath
-->
<style>
    .markdown-body .anchor{
        float: left;
        margin-top: -8px;
        margin-left: -20px;
        padding-right: 4px;
        line-height: 1;
        opacity: 0;
    }
    
    .markdown-body .anchor .anchor-icon{
        font-size: 15px
    }
</style>
<script>
    $(document).ready(function() {
        let nodes = document.querySelector(".markdown-body").querySelectorAll("h1,h2,h3")
        for(let node of nodes) {
            var anchor = document.createElement("a")
            var anchorIcon = document.createElement("i")
            anchorIcon.setAttribute("class", "fa fa-anchor fa-lg anchor-icon")
            anchorIcon.setAttribute("aria-hidden", true)
            anchor.setAttribute("class", "anchor")
            anchor.setAttribute("href", "#" + node.getAttribute("id"))
            
            anchor.onmouseover = function() {
                this.style.opacity = "0.4"
            }
            
            anchor.onmouseout = function() {
                this.style.opacity = "0"
            }
            
            anchor.appendChild(anchorIcon)
            node.appendChild(anchor)
        }
    })
</script>
	
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?671e6ffb306c963dfa227c8335045b4f";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
		
        })();
    </script>

</head>


<body>
  <!--[if lt IE 10]>
<div class="alert-danger" role="alert">你的浏览器实在太太太旧了，放学别走，升级完浏览器再说！<a target="_blank" class="alert-link" href="http://browsehappy.com">立即升级</a></div>
<![endif]-->
  <input id="nm-switch" type="hidden" value="true"> <header class="g-header">
    <div class="g-logo">
      <a href="/"></a>
    </div>
    <i id="menu-toggle" class="iconfont icon-menu"></i>
    <nav class="g-nav">
        <ul>
            
            <li><a href="/">home</a></li>
            
            <li><a href="/tags.html">tags</a></li>
            
        </ul>
    </nav>
</header>


  <header
    class="g-banner post-header post-pattern-circuitBoard bgcolor-default "
    data-theme="default"
  >
    <div class="post-wrapper">
      <div class="post-tags">
        
          
            <a href="/tags.html#DeepLearning" class="post-tag">DeepLearning</a>
          
            <a href="/tags.html#ReadPaper" class="post-tag">ReadPaper</a>
          
        
      </div>
      <h1>Region Proposal by Guided Anchoring</h1>
      <div class="post-meta">
        <span class="post-meta-item"><i class="iconfont icon-author"></i>刘浩光</span>
        <time class="post-meta-item" datetime="23-03-06"><i class="iconfont icon-date"></i>06 Mar 2023</time>
      </div>
    </div>
    
    <div class="filter"></div>
      <div class="post-cover" style="background: url('/assets/images/header/GA-RPN.png') center no-repeat; background-size: cover;"></div>
    
  </header>

  <div class="post-content visible">
    

    <article class="markdown-body">
      <h2 id="一种利用语义特征引导的锚框自适应方法ga">一种利用语义特征引导的锚框自适应方法（GA）</h2>

<blockquote>
  <p>文章发表于 CVPR 2019.</p>
</blockquote>

<p>论文链接地址：<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Region_Proposal_by_Guided_Anchoring_CVPR_2019_paper.pdf">Region Proposal by Guided Anchoring</a></p>

<h3 id="1-introduction">1. Introduction</h3>

<p>合理的锚框设计有两个一般规则：对齐和一致性。对齐是指：使用卷积特征作为锚框表示时，锚框中心需要与特征图像素很好地对齐。一致性是指：在特征图不同位置上，感受野和语义范围应该与对应锚框的规模和形状一致。</p>

<p>对于大多数 anchor_based 的检测方法，anchors 由统一方案定义，其中特征图中的每个位置都与 k 个具有预定义比例和纵横比的 anchors 相关联。均匀锚框预设方案并不一定是锚框的最佳制备方案（<strong>次优</strong>），这种方案可能导致两个问题；</p>

<ul>
  <li>必须为不同的问题预先定义一组固大小、定长宽比的整齐锚框，这种设计可能会妨碍检测器的速度和准确性。</li>
  <li>为了保持足够高的提议查全率（recall），需要预设大量的锚框，这样会造成锚框大多对应于与兴趣对象无关的假候选点。同时，大量的锚框会导致大量的计算成本，特别是当管道在提案阶段涉及一个重分类器时。</li>
</ul>

<p>由于观察到物体不是均匀分布在图像上。物体的尺度也与图像内容、位置和场景的几何形状密切相关。根据这种观察，<strong>将采用两步生成稀疏锚框：</strong>首先识别可能包含对象的子区域，然后确定不同位置的形状。（引导锚定模块）</p>

<p>可学习锚指锚框的比例和纵横比是可变的，它会打破锚框设计的一致性规则。为了使得可学习锚框得以精确的分类和回归，不同的特征图像素必须学习适应相应锚框的自适应表示。（锚框几何调整模块）</p>

<p><strong>本文贡献主要有以下四点：</strong></p>

<ol>
  <li>提出了一种新的锚定方案，该方案能够预测非均匀和任意形状的锚，而不是密集和预定义的锚</li>
  <li>用两个因式条件分布构造联合锚分布，并设计两个模块分别对其进行建模</li>
  <li>研究了将特征与相应锚框对齐的重要性，并设计了基于锚框形状的特征自适应模块来细化特征</li>
  <li>研究了 two-stage 检测器的高质量提议的使用，并提出了一种提高训练模型性能的方案</li>
</ol>

<h3 id="2-methodology">2. Methodology</h3>

<p>整个工作的目标是开发一个更有效的锚定方案，以安排具有可学习形状的锚框，考虑到物体的位置和形状的非均匀分布。</p>

<p>物体的位置和形状可以用 $(x, y, w, h)$ 形式的4元组来表示，其中 $(x, y)$ 是中心的空间坐标，$w$ 是宽度，$h$ 是高度。假设从给定的图像 $I$ 中画出一个物体，那么它的位置和形状可以被认为遵循以 $I$ 为条件的分布，公式表示为：</p>

\[p(x,y,w,h|I) = p(x,y|I)p(w,h|x,y,I)\]

<p>这种分解得到两个重要的直觉：</p>

<ol>
  <li>给定一幅图像，物体可能只存在于某些区域</li>
  <li>物体的形状，即尺寸和纵横比，与它的位置密切相关</li>
</ol>

<p>根据上述两个直觉，设计出一个锚框生成模块（自适应），如下图所示：</p>

<p><img src="/assets/images/context/GA-framework.png" alt="GA-framework" /></p>

<p>首先将各层特征图 $F_i$ 送入位置预测分支和形状预测分支，分别产生一个物体可能存在的概率图和位置相关的形状。再通过选择位置概率高于某阈值的位置和每个所选位置最可能的形状来生成一组锚框。</p>

<p>由于锚框的形状可能不同，不同位置的特征应该捕获不同范围内的视觉内容（打破一致性原则）。考虑到这一点，进一步引入了特征自适应模块，该模块根据锚框形状对特征进行自适应。</p>

<p>==请注意，在设计中，锚生成参数在所有涉及的特征级别上共享，因此该方案是参数高效的。==</p>

<p><strong>2.1 Anchor Location Prediction</strong></p>

<p>如图 1 所示，概率图 $p(\cdot｜F_i)$ 的大小与特征图 $F_i$ 大小一致，通道数为1。其中每个 $p(i,j｜F_i)$  对应于原图坐标 $(\frac{i+1}{2}s,\frac{j+1}{2}s)$，其中 s 为该特征图的步长，该项的值表示物体的中心存在于该位置的概率。</p>

<p>实现中，该概率图是由 $N_L$ 网络进行预测。网络将 $1 \times 1$ 卷积应用于特征图 $F_i$，获得物体性分数 map，然后通过 sigmoid 函数将其转化为概率值。（一层 Conv + sigmoid 在效率和准确度之间取得了很好的平衡）</p>

<p>通过生成的概率图，可以选择相对概率值高的阈值 $\epsilon_L$ 来确定可能寻在物体的区域（保持相同召回率情况下可过滤掉90%的区域）。由于不需要考虑那些被排除的区域，可以将后续的卷积层替换为掩码卷积，以获得更有效的推理。</p>

<p><strong>2.2 Anchor Shape Prediction</strong></p>

<p>在确定物体可能的位置之后，下一步是确定每个位置上可能存在的物体的形状。这是由锚的形状预测分支完成的，如图 1 所示。这个分支与传统的边界盒回归有很大的不同，因为它不会改变锚框的位置，也不会导致锚框和锚框特征之间的错位。具体来说，给定一个特征图 $F_i$，该分支将预测每个位置的最佳形状 (w, h)，即使之达到与最近的 ground-truth 包围框的最高覆盖率的形状。</p>

<p>根据经验发现，直接预测这两个数字是不稳定的，因为它们的范围很大。相反，采用以下转换效果更好：</p>

\[w=\sigma \cdot s \cdot e^{dw}, \space \space \space \space h=\sigma \cdot s \cdot e^{dh}\]

<p>其中 s 为步长，$\sigma$ 为经验比例因子（一般设置 $\sigma$ = 8）。这种非线性转换将将输出空间从近似 $[0, 1000]$ 投影到$[-1, 1]$，从而可以获得更容易且稳定的学习。</p>

<p>实现中，该形状由 $N_S$ 网络进行预测。网络将 $1 \times 1$ 卷积应用于特征图 $F_i$，生成包含 $dw$ 和 $dh$ 的双通道映射，并通过上述公式进行转换。</p>

<p>这种设计与传统的锚定方案有本质上的不同，因为每个位置只与动态预测形状的一个锚框相关联，而不是与一组预定义形状的锚框相关联。实验表明，由于位置和形状之间的密切关系，此方案可以获得比基线方案（统一均匀生成方案）更高的召回率。由于它允许任意的纵横比（可学习性），此方案可以更好地捕捉那些极高或极宽的物体。</p>

<p><strong>2.3 Anchor-Guided Feature Adaptation</strong></p>

<p>在常规的 anchor-based 检测器中，锚框在整个特征图上是均匀的，即锚框在每个位置上具有相同的形状和比例。因此，特征图可以学习一致的表示。在本方案中，锚框形状因位置而异，这种情况下，发现遵循前面的规定并不是一个很好的选择（卷积是在特征图上统一应用）。理想情况是，大型锚框应该在在大范围内编码内容，小型锚框相应的应该具有较小的作用域。</p>

<p>根据此直觉，进一步设计了锚框引导的特征自适应组件，它将根据锚的形状在每个单独的位置上进行特征转换，表示如下：</p>

\[f_i^{'} = N_T(f_i, w_i, h_i)\]

<p>其中 $f_i$ 为第 i 个位置的特征，$(w_i, h_i)$ 为对应的锚框形状。</p>

<p>实现中，采用 $3\times3$ 的可变性卷积来实现 $N_T$ 网络。如图 1 所示，首先从锚框预设分支拿到一个偏移场，然后对偏移场的原始特征进行可变性卷积，得到 $f_i^{‘}$ (自适应后特征)。之后可以进行进一步的分类和边界框的回归。</p>

<p><strong>2.4 Training</strong></p>

<p><strong>a. Joint objective</strong></p>

<p>此框架使用多任务损失的端到端方式进行优化。除了传统的分类损耗 $L_{cls}$ 和回归损耗 $L_{reg}$ 外，还引入了锚定位 $L_{loc}$ 和锚形状预测 $L_{shape}$ 两种额外的损失。他们以以下的损失 $L$ 共同优化：</p>

\[L = \lambda_1 \cdot L_{loc} + \lambda_2 \cdot L_{shape} + L_{cls} + L_{reg}\]

<p><strong>b. Anchor location targets</strong></p>

<p>为了训练锚框定位分支，对于每个图像，都需要一个二进制标签映射，用 1 表示放置锚框的有效位置，0 为无效。此处采用 ground-truth 边界框来指导标签映射的生成（期望物体中心附近放置更多锚框，远离中心尽量少）。</p>

<p>用 $(x_g,y_g,w_g,x_g)$ 表示真值框，经其映射到各特征图，得到 $(x_g^{‘},y_g^{‘},w_g^{‘},x_g^{‘})$ ，将 $R(s,y,w,h)$ 表示为中心为 $(x,y)$ ，大小为 $w \times h$ 的矩形区域。更具上述期望，定义三种类型区域：</p>

<ul>
  <li>center region: $CR=R(x_g^{‘},y_g^{‘},\sigma_1 w_g^{‘},\sigma_1 x_g^{‘})$  表示为中心区域，其中的像素被分配为正样本</li>
  <li>ignore region: $IR=R(x_g^{‘},y_g^{‘},\sigma_2 w_g^{‘},\sigma_2 x_g^{‘}) \setminus CR$  是一个较大的 $(\sigma_2&gt;\sigma_1)$ 不包括 $CR$ 的区域，表示为忽略区域，训练时被排除</li>
  <li>outside region: $OR$ 不包含 $CR$ 和 $OR$ 的特征图区域，像素被分配为负样本</li>
</ul>

<p><img src="/assets/images/context/GA-mul-loc.png" alt="Anchor-location" /></p>

<p>此处还考虑了相邻特征图的影响，具体来说，每个级别的特征图应该只针对特定比例范围的对象，因此仅在特征图与目标对象的比例范围匹配时才在特征图上分配 $CR$。相邻层的相同区域设置为IR，如图 2 所示（$CR$ 可以抑制 $IR$ ，$IR$ 可以抑制 $OR$）。由于 $CR$ 通常只占整个特征图的一小部分，所以使用 Focal Loss 来训练位置分支。</p>

<p><strong>c. Anchor shape targets</strong></p>

<p>由于本方案中锚框的 w 和 h 不是预定的，而是变量，就无法直接进行分配并计算 IoU。为了克服这个问题，进行如下函数优化：</p>

\[vIoU(a_{wh},gt)=\max_{w&gt;0,h&gt;0}IoU_{normal}(a_{wh},gt)\]

<p>其中 $IoU_{normal}$ 为原始 $IoU$ 定义，w 和 h 为变量，$a_{wh}$ 为任意位置 $(x_0,y_0)$ 处的锚框，$gt$ 为真值框。但由于 $vIoU(a_{wh},gt)$ 表达式的复杂性，很难在网络中有效的实现。因此采用另一种方法来近似。在 $(x_0,y_0)$ 处，对 w 和 h 的一些公共值进行采样，以模拟所有 w 和 h 的枚举。然后用 $gt$ 计算这些采样锚的 $IoU$，并使用最大值作为 $vIoU(a_{wh},gt)$ 的近似值。</p>

<p>在实验中，采用 RetinaNet 中的 9 种不同尺度和横纵比进行采样模拟（采样越多，模拟越精确，但计算成本更重）。采用 bound IoU Loss 来训练形状分支。损失函数表达式如下：</p>

\[L_{shape}=L_1(1-min( \frac{w}{w_g}, \frac{w_g}{w})) + L_1(1-min( \frac{h}{h_g}, \frac{h_g}{h}))\]

<p>其中 $(w, h)$ 和 $(w_g, h_g)$ 分别表示为预测的宽高和真实的宽高，$L_1$ 为 Smooth L1 Loss。</p>

<p><strong>d. The Use of High-quality Proposals</strong></p>

<p>GA-RPN 相对于 RPN 有两点优势：（1）正提议数量更多；（2）高 $IoU$ 提议的比率更为显著。</p>

<p>直接使用 GA-RPN 代替 RPN 并不能带来很好的收益（涨点不到 1）。由于使用高质量提议的前提是根据提议的分布调整训练样本的分布，因此，与 RPN 相比，设置更高的正/负阈值，并在使用 GA-RPN 时使用更少的训练样本，可以获得更高的收益。</p>

<p>此外，可以使用 GA-RPN 通过微调来提高训练好的两阶段检测器。具体来说，给定一个训练好的模型，放弃建议生成组件（RPN)，并使用预先计算的 GA-RPN 对它进行几个 epoch (默认为 3 个 epoch ) 的微调，GA-RPN 也用于推理。这种简单的微调方案只需要几个 epoch 的时间成本，就可以获得进一步大幅度的性能提升。</p>

<h3 id="3-experiments">3. Experiments</h3>

<p>下述所有实验均在 MS COCO 2017 上进行。</p>

<p>如果没有特殊说明，所有实验采用 ResNet-50 作为主干网络，FPN 作为颈部网络。图像调整大小为 $1333 \times 800$ 并不改变横纵比。设置参数 $\sigma_1=0.2, \space \sigma_2=0.5$。多任务损函数中，设置 $\lambda_1=1, \space \lambda_2=0.1$ 来平衡位置和形状预测分支。</p>

<p>RPN 的结果用平均召回率（AR）来衡量。AR 是阈值从 0.5 到 0.95 的召回率的平均值。每张图像100、300和1000个提议的 AR 分别表示为 $AR_{100}、AR_{300}$ 和 $AR_{1000}$。小型、中型和大型对象（$AR_S、AR_M、AR_L$）的 AR 为 100 个提议计算。检测结果使用标准 COCO 度量进行评估，该度量为 IoU 的 mAP 从 0.5 到 0.95。</p>

<p><img src="/assets/images/context/GA-result1.png" alt="GA-result" /></p>

<p>其中，RPN + 9 anchors 为使用 3 个尺度 3 个比率；RPN + Focal Loss 和 RPN + Bounded IoU Loss 分别为替换 RPN 中原有的 Cross-Entropy Loss 和 Smooth L1 Loss；RPN + Iterative 为采用两次 RPN head，并且中间用 $3 \times 3$ 卷积层连接；RefineRPN 为锚框根据 FPN前后特征进行两次回归和分类。 可以看到，AR 的值都在显著的提升，GA-RPN 的平均查全率最大，尤其表现在中大型目标上。</p>

<p>同时，其对于 AP 的提升也十分明显，应用在 anchor-based 的检测器，在 COCO 数据集上基本会得到 2 个点左右的 mAP 提升。如下图所示：</p>

<div align="center">
    <img src="/assets/images/context/GA-result2.png" width="60%" />
</div>

<p>下图为 RPN 和 GA-RPN 的可视化结果，可以看到 GA-RPN 提议的框更少，但更精确。</p>

<div align="center">
	<img src="/assets/images/context/GA-result3.png" width="80%" />
</div>

<p>更多详细的消融实验见论文原文，实现代码详见 mmdetation 官方仓库。</p>

    </article>

    
    <div class="social-share-wrapper">
      <div class="social-share"></div>
    </div>
    
  </div>

  <section class="author-detail">
    <section class="post-footer-item author-card">
      <div class="avatar">
        <img src="/assets/icons/icon.jpg" alt="">
      </div>
      <div class="author-name" rel="author">刘浩光</div>
      <div class="bio">
        <p>CVer  深度学习者</p>
      </div>
      
      <ul class="sns-links">
        
        <li>
          <a href="//github.com/gravity-lhg" target="_blank">
                    <i class="iconfont icon-github"></i>
                </a>
        </li>
        
        <li>
          <a href="//zhihu.com/people/gravity-74-50" target="_blank">
                    <i class="iconfont icon-zhihu"></i>
                </a>
        </li>
        
      </ul>
      
    </section>
    <section class="post-footer-item read-next">
      
      <div class="read-next-item">
        <a href="/2023/03/13/First_compiling.html" class="read-next-link"></a>
        <section>
          <span>Compiling Stuffs</span>
          <p>GCC/G++ 编译、make 编译、CMake 编译</p>
        </section>
        
        <div class="filter"></div>
        <img src="/assets/images/header/compiling.png" alt="">
        
     </div>
      

      
      <div class="read-next-item">
        <a href="/2023/03/05/binarySearch.html" class="read-next-link"></a>
          <section>
            <span>Binary Search Algorithm</span>
            <p>二分查找算法的 C++ 实现与 STL 库调用实现</p>
          </section>
          
          <div class="filter"></div>
          <img src="/assets/images/header/binary-search.png" alt="">
          
      </div>
      
    </section>
    
    <section class="post-footer-item comment">
      <div id="disqus_thread"></div>
      <div id="gitalk_container"></div>
    </section>
  </section>

  <footer class="g-footer">
  <section>刘浩光的个人博客 ©
  
  
  2023
  </section>
  <section>Powered by <a href="//jekyllrb.com">Jekyll</a></section>
</footer>


  <script src="/assets/js/social-share.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
    socialShare('.social-share', {
      sites: [
        
          'wechat'
          ,
          
        
          'weibo'
          ,
          
        
          'douban'
          ,
          
        
          'twitter'
          
        
      ],
      wechatQrcodeTitle: "分享到微信朋友圈",
      wechatQrcodeHelper: '<p>扫码后点击右上角</p><p>将本文分享至朋友圈</p>'
    });
  </script>

  
	
  

  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/index.min.js"></script>
</body>

</html>
